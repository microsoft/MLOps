{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Exercise 5 - Deploying a Model into Production\n\nIn [the previous exercise](./03%20-%20Compute%20Contexts.ipynb), you explored options for running experiments on local and remote compute to train machine learning models. Int his exercise, you'll build on that work and deploy a model as a production web service.\n\n> **Important**: This exercise assumes you have completed the previous exercises in this series - specifically, you must have:\n>\n> - Created an Azure ML Workspace.\n> - Uploaded the diabetes.csv data file to the workspace's default datastore.\n> - Registered a **Diabetes Dataset** dataset in the workspace.\n> - Trained and registered at least one **diabetes_model** model in the workspace.\n>\n> If you haven't done that, what are you waiting for?\n\n## Task 1: Connect to Your Workspace\n\nThe first thing you need to do is to connect to your workspace using the Azure ML SDK. Let's start by ensuring you still have the latest version installed (if you ended and restarted your Azure Notebooks session, the environment may have been reset)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!pip install --upgrade azureml-sdk[notebooks]\n\nimport azureml.core\nprint(\"Ready to use Azure ML\", azureml.core.VERSION)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now you're ready to connect to your workspace. When you created it in the previous exercise, you saved its configuration; so now you can simply load the workspace from its configuration file.\n\n> **Note**: If the authenticated session with your Azure subscription has expired since you completed the previous exercise, you'll be prompted to reauthenticate."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core import Workspace\n\n# Load the workspace from the saved config file\nws = Workspace.from_config()\nprint('Ready to work with', ws.name)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Task 2: Deploy a Model as a Web Service\n\nIn the previous exercise, you trained and registered a machine learnming model that classifies patients based on the likelihood of them having diabetes. This model could be used in a production environment such as a doctor's surgery where only patients deemed to be at risk need to be subjected to a clinical test for diabetes. To support this scenario, you will deploy the model as a web service.\n\nFirst, let's determine what models you have registered in the workspace."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core import Model\n\nfor model in Model.list(ws):\n    print(model.name, 'version:', model.version)\n    for tag_name in model.tags:\n        tag = model.tags[tag_name]\n        print ('\\t',tag_name, ':', tag)\n    for prop_name in model.properties:\n        prop = model.properties[prop_name]\n        print ('\\t',prop_name, ':', prop)\n    print('\\n')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Right, now let's get the model that we want to deploy. By default, if we specify a model name, the latest version will be returned."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "model = ws.models['diabetes_model']\nprint(model.name, 'version', model.version)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We're going to create a web service to host this model, and this will require some code and configuration files; so let's create a folder for those."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\n\nfolder_name = 'diabetes_service'\n\n# Create a folder for the web service files\nexperiment_folder = './' + folder_name\nos.makedirs(folder_name, exist_ok=True)\n\nprint(folder_name, 'folder created.')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The web service where we deploy the model will need some Python code to load the input data, get the model from the workspace, and generate and return predictions. We'll save this code in a *scoring* file that will be deployed to the web service:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%writefile $folder_name/score_diabetes.py\nimport json\nimport numpy as np\nimport os\nimport joblib\nfrom azureml.core.model import Model\nimport azureml.train.automl # Required for AutoML models\n\n# Called when the service is loaded\ndef init():\n    global model\n    # Get the path to the deployed model file and load it\n    model_path = Model.get_model_path('diabetes_model')\n    model = joblib.load(model_path)\n\n# Called when a request is received\ndef run(raw_data):\n    # Get the input data - the features of patients to be classified.\n    data = json.loads(raw_data)['data']\n    # Get a prediction from the model\n    predictions = model.predict(data)\n    # Get the corresponding classname for each prediction (0 or 1)\n    classnames = ['not-diabetic', 'diabetic']\n    predicted_classes = []\n    for prediction in predictions:\n        predicted_classes.append(classnames[prediction])\n    # Return the predictions as JSON\n    return json.dumps(predicted_classes)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The web service will be hosted in a container, and the container will need to install any required Python dependencies when it gets initialized. In this case, our scoring code requires **scikit-learn**, so we'll create a .yml file that tells the container host to install this into the environment."
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "from azureml.core.conda_dependencies import CondaDependencies \n\n# Add the dependencies for our model (AzureML defaults is already included)\nmyenv = CondaDependencies()\nmyenv.add_conda_package(\"scikit-learn\")\nmyenv.add_pip_package(\"azureml-sdk[automl]\") # Required for AutoML models\n\n# Save the environment config as a .yml file\nenv_file = folder_name + \"/diabetes_env.yml\"\nwith open(env_file,\"w\") as f:\n    f.write(myenv.serialize_to_string())\nprint(\"Saved dependency info in\", env_file)\n\n# Print the .yml file\nwith open(env_file,\"r\") as f:\n    print(f.read())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now you're ready to deploy. We'll deploy the container a service named **diabetes-service**. The deployment process includes the following steps:\n\n1. Define an inference configuration, which includes the scoring and environment files required to load and use the model.\n2. Define a deployment configuration that defines the execution environment in which the service will be hosted. In this case, an Azure Container Instance.\n3. Deploy the model as a web service.\n4. Verify the status of the deployed service.\n\n> **More Information**: For more details about model deployment, and options for target execution environments, see the [documentation](https://docs.microsoft.com/en-gb/azure/machine-learning/service/how-to-deploy-and-where).\n\nDeployment will take some time as it first runs a process to create a container image, and then runs a process to create a web service based on the image. When deployment has completed successfully, you'll see a status of **Healthy**."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.webservice import AciWebservice\nfrom azureml.core.model import InferenceConfig\n\n# Configure the scoring environment\ninference_config = InferenceConfig(runtime= \"python\",\n                                   source_directory = folder_name,\n                                   entry_script=\"score_diabetes.py\",\n                                   conda_file=\"diabetes_env.yml\")\n\ndeployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n\nservice_name = \"diabetes-service\"\n\nservice = Model.deploy(ws, service_name, [model], inference_config, deployment_config)\n\nservice.wait_for_deployment(True)\nprint(service.state)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Take a look at your workspace in the [Azure portal](https://portal.azure.com) and view the **Images** and **Deployments** tabs, which show the web service container images and deployed services respectively.\n\nYou can also enumerate the web services using the following code:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "for webservice_name in ws.webservices:\n    webservice = ws.webservices[webservice_name]\n    print(webservice.name)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Task 3: Use the Web Service\n\nWith the service deployed, now you can consume it from a client application."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import json\n\nx_new = [[2,180,74,24,21,23.9091702,1.488172308,22]]\nprint ('Patient: {}'.format(x_new[0]))\n\n# Convert the array to a serializable list in a JSON document\ninput_json = json.dumps({\"data\": x_new})\n\n# Call the web service, passing the input data (the web service will also accept the data in binary format)\npredictions = service.run(input_data = input_json)\n\n# Get the predicted class - it'll be the first (and only) one.\npredicted_classes = json.loads(predictions)\nprint(predicted_classes[0])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "You can also send multiple patient observations to the service, and get back a prediction for each one."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import json\n\n# This time our input is an array of two feature arrays\nx_new = [[2,180,74,24,21,23.9091702,1.488172308,22],\n         [0,148,58,11,179,39.19207553,0.160829008,45]]\n\n# Convert the array or arrays to a serializable list in a JSON document\ninput_json = json.dumps({\"data\": x_new})\n\n# Call the web service, passing the input data\npredictions = service.run(input_data = input_json)\n\n# Get the predicted classes.\npredicted_classes = json.loads(predictions)\n   \nfor i in range(len(x_new)):\n    print (\"Patient {}\".format(x_new[i]), predicted_classes[i] )",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The code above uses the Azure ML SDK to connect to the containerized web service and use it to generate predictions from your diabetes classification model. In production, a model is likely to be consumed by business applications that do not use the Azure ML SDK, but simply make HTTP requests to the web service.\n\nLet's determine the URL to which these applications must submit their requests:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "endpoint = service.scoring_uri\nprint(endpoint)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now that you know the endpoint URI, an application can simply make an HTTP request, sending the patient data in JSON (or binary) format, and receive back the predicted class(es)."
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "import requests\nimport json\n\nx_new = [[2,180,74,24,21,23.9091702,1.488172308,22],\n         [0,148,58,11,179,39.19207553,0.160829008,45]]\n\n# Convert the array to a serializable list in a JSON document\ninput_json = json.dumps({\"data\": x_new})\n\n# Set the content type\nheaders = { 'Content-Type':'application/json' }\n\npredictions = requests.post(endpoint, input_json, headers = headers)\npredicted_classes = json.loads(predictions.json())\n\nfor i in range(len(x_new)):\n    print (\"Patient {}\".format(x_new[i]), predicted_classes[i] )",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}