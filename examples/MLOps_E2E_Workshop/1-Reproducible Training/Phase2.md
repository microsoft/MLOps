# Phase 2: Refactor Model Training Code

Now you can reproduce how the data science team's code in the notebook successfully trains a model to predict if drivers are safe. The team would like to continue to ensure quality and improve the model code as well centrally share models and results with others during development.  All of these goals are challenging with the training code embedded in a notebook and no centralized services are being utilized to facilitate sharing.  

What can be done to help the team with these goals?
Extracting the notebook code into Python scripts is an important step to ensure code quality via lint and unit tests (covered in challenge 4) and also cleanly execute on remote compute targets (covered in challenge 3).
Logging parameter values and model validation metrics centrally with the Azure Machine learning service makes it easy to compare the performance of different versions of the model and the parameters they were trained with.

## Prerequisites

Before starting this challenge, ensure you have the following prerequisite requirements in place from Challenge 1:

* An Azure Machine Learning workspace with a compute instance.
* The experimentation notebook provided by the data science team.

## Resources

* [Documentation - Install the Azure Machine Learning SDK for Python](https://docs.microsoft.com/python/api/overview/azureml-sdk/install)
* [Notebook: Training Models](https://github.com/MicrosoftDocs/mslearn-aml-labs/blob/master/02-Training_Models.ipynb)
* [*Microsoft Learn* module - Train a machine learning model with Azure Machine Learning](https://docs.microsoft.com/learn/modules/train-local-model-with-azure-mls/index)
* [Documentation - Train models with Azure machine Learning](https://docs.microsoft.com/azure/machine-learning/concept-train-machine-learning-model)
* [Documentation - How to build scikit-learn models at scale with Azure Machine Learning](https://docs.microsoft.com/azure/machine-learning/how-to-train-scikit-learn)
* [Documentation - How to monitor Azure ML experiment runs and metrics](https://docs.microsoft.com/azure/machine-learning/how-to-track-experiments)


## Tasks

1. Refactor the notebook code from Challenge 1 to create a Python script that uses the training data to train and evaluates the model, and saves the resulting model as with the name **lgbm_binary_model.pkl** in a folder named **outputs**.
2. On your Compute Instance, install the latest version of the Azure ML SDK. Then in a new notebook, run the training script as an experiment, and review the outputs generated by the experiment run in [Azure Machine Learning studio](https://ml.azure.com) - these should include the experiment run log files and the trained model.
3. Modify your training script to:
    * Receive the **learning_rate** parameter as an argument, and use the argument value in the **parameters** dictionary used to train the model.
    * Log each of the parameter values used to train the model, and the **AUC** [(Area under the curve)](https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5) evaluation metric in the experiment run.
4. Rerun the experiment, and verify that the metrics are logged.
5. Add code to your new notebook to retrieve the trained model from the experiment run, and register the model with the name **lgbm_binary_model.pkl** in your Azure Machine Learning workspace  - using tags to record the **AUC** metric in the registration.

### Hints

* Use an **Estimator** to run the script as an Azure Machine Learning experiment - base your code on the [Training Models](https://github.com/MicrosoftDocs/mslearn-aml-labs/blob/master/02-Training_Models.ipynb) exercise notebook for an example of running a training script with an estimator, logging metrics, and registering the resulting model. This exercise is part of the Microsoft Learn *Train a machine learning model with Azure Machine Learning* module.
* To connect to your workspace from the Jupyter environment, best practice when using the Azure ML SDK is to use the `Workspace.from_config()` method to read the connection information from a workspace configuration file. On compute instances in your workspace, this file is created automatically. When using your own development environment, you must create this file in the same folder as your code. See [Configure a development environment for Azure Machine Learning](https://docs.microsoft.com/azure/machine-learning/how-to-configure-environment#workspace) for details.
* To run a script as an experiment, you should create a folder for the script file and copy the training data into this folder so that the script references the data using the appropriate relative path.
* Specify a **'local'** compute target for running your experiment. In production, you would likely use a remote training cluster (to which the entire experiment folder would be copied automatically when the experiment is run), but remote compute can take a while to initialize so testing locally with this relatively small volume of data is generally quicker.


### Success Criteria

To successfully complete this task, you must:

* Refactor the model training code into a separate python script that can be run independently of the notebook. The script must contain arguments so that it can be used to train models with different parameters.
* Successfully run your experiment on Azure Machine Learning and be able to see the logged metrics and trained model in the run results.
* Successfully register the trained model.


## Reflect

After completing this challenge, consider the following questions:

* What is the benefit of separating the training code out of the notebook?
* What is the benefit of running your experiments using Azure Machine Learning?

## Explore Further

In this solution, you used a local data file to train the model. To increase scalability and flexibility, you can store this data centrally in an Azure Machine Learning *datastore*, and you can create a *dataset* to simplify data ingestion and enable data versioning. See the following resources for more information:

* [Documentation - How to access data in Azure storage services](https://docs.microsoft.com/azure/machine-learning/how-to-access-data)
* [Documentation - How to create Azure Machine Learning datasets](https://docs.microsoft.com/azure/machine-learning/how-to-create-register-datasets).
* [Documentation - How to train with datasets](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-train-with-datasets).
